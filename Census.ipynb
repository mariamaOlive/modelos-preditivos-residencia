{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Modelos preditivos - Dataset do Censo\n",
    "\n",
    "## Grupo:\n",
    "- Lucas Natan Correia Couri\n",
    "- Mariama Celi Serafim de Oliveira\n",
    "- Laianna Lana Virginio da Silva\n",
    "- Priscilla Amarante de Lima\n",
    "- Liviany Reis Rodrigues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 6138\n",
    "columns_name = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'class']\n",
    "df = pd.read_csv(\"Dados/adult.data\", names=columns_name, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explorar a base de dados para mostrar outliers, nivel de separatividade dos dados em relação as classes (grafico de dispersao), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workclass'] = df['workclass'].astype('category')\n",
    "df['education'] = df['education'].astype('category')\n",
    "df['marital-status'] = df['marital-status'].astype('category')\n",
    "df['occupation'] = df['occupation'].astype('category')\n",
    "df['relationship'] = df['relationship'].astype('category')\n",
    "df['race'] = df['race'].astype('category')\n",
    "df['sex'] = df['sex'].astype('category')\n",
    "df['native-country'] = df['native-country'].astype('category')\n",
    "df['class'] = df['class'].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolvendo o problema da Holanda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No dataset de treino há apenas uma obvservação como \" Holand-Netherlands\", diante do tamanho do dataset (mais de 30mil linhas) optou-se por remover essa única linha com native-country=\" Holand-Netherlands\" de forma a evitar problemas de ausência do valor no dataset de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['native-country']!=\" Holand-Netherlands\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenchendo dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratamento_faltantes(df, columns_name):\n",
    "    ## Printa os atributos com dados faltantes (\" ?\")\n",
    "    for coluna in columns_name:\n",
    "        if len(df[df[coluna] == \" ?\"]) > 0:\n",
    "            print(coluna)\n",
    "            print(len(df[df[coluna] == \" ?\"]))\n",
    "    \n",
    "    ## Tratamento dos dados faltantes, transforma para numerico, substitui \" ?\" por NaN e interpola os NaN\n",
    "    atr_faltantes = [\"workclass\", \"occupation\", \"native-country\"]\n",
    "    for atr in atr_faltantes:\n",
    "        categorias_atr = df.groupby(atr).sum().index.tolist()\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        label_encoder.fit(categorias_atr)\n",
    "        df[f\"{atr}-num\"] = label_encoder.transform(df[atr])\n",
    "        df[f\"{atr}-num\"] = df[f\"{atr}-num\"].replace(0, np.nan)\n",
    "        df[f\"{atr}-num\"] = df[f\"{atr}-num\"].interpolate(method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratamento_faltantes(df, columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for coluna in columns_name:\n",
    "#    if len(df[df[coluna] == \" ?\"]) > 0:\n",
    "#        print(coluna)\n",
    "#        print(len(df[df[coluna] == \" ?\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada atributo que tem dados faltantes vamos preencher utilizando a interpolação, para isso passamos para numerico antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atr_faltantes = [\"workclass\", \"occupation\", \"native-country\"]\n",
    "#for atr in atr_faltantes:\n",
    "#    categorias_atr = df.groupby(atr).sum().index.tolist()\n",
    "#    label_encoder = preprocessing.LabelEncoder()\n",
    "#    label_encoder.fit(categorias_atr)\n",
    "#    df[f\"{atr}-num\"] = label_encoder.transform(df[atr])\n",
    "#    df[f\"{atr}-num\"] = df[f\"{atr}-num\"].replace(0, np.nan)\n",
    "#    df[f\"{atr}-num\"] = df[f\"{atr}-num\"].interpolate(method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checando outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours-per-week'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours-per-week'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-gain'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-gain'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-loss'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-loss'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1 = dados['idade_log'].quantile(q=0.25)\n",
    "#q3 = dados['idade_log'].quantile(q=0.75)\n",
    "#iqr = q3 - q1\n",
    "#print(iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colunas redundantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "education e education-num significam a mesma coisa, vamos utilizar education-num e dropar education (education-num já é a codificação ordinal de education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education-num'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: Plotar região"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequência das variáveis categóricas (Value counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['marital-status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando e processando conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Dados/adult.test\", names=columns_name, index_col=False, skiprows=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratamento_faltantes(df_test, columns_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação das variáveis categóricas (variáveis nominais, faremos One Hot Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoder(df):\n",
    "    colunas_cat = [\"workclass-num\",\"marital-status\", \"occupation-num\", \"relationship\", \"race\", \"sex\", \"native-country-num\"]\n",
    "    for coluna in colunas_cat:\n",
    "        print(coluna)\n",
    "        df_coluna = pd.get_dummies(df[coluna], prefix=coluna)\n",
    "        df = df.join(df_coluna)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = onehot_encoder(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = onehot_encoder(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando variáveis contínuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalize = MinMaxScaler()\n",
    "df[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]] = normalize.fit_transform(df[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]])\n",
    "df_test[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]] = normalize.fit_transform(df_test[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo conjuntos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop([\"class\", \"education\", \"workclass\", \"workclass-num\",\"marital-status\", \"occupation\", \"occupation-num\", \"relationship\", \"race\", \"sex\", \"native-country\", \"native-country-num\"], axis = 1).to_numpy()\n",
    "y_train = df[\"class\"].values\n",
    "X_test = df_test.drop([\"class\", \"education\", \"workclass\", \"workclass-num\",\"marital-status\", \"occupation\", \"occupation-num\", \"relationship\", \"race\", \"sex\", \"native-country\", \"native-country-num\"], axis = 1).to_numpy()\n",
    "y_test = df_test[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"class\", \"education\", \"workclass\", \"workclass-num\",\"marital-status\", \"occupation\", \"occupation-num\", \"relationship\", \"race\", \"sex\", \"native-country\", \"native-country-num\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Realizar busca com o gridsearch ou randonsearhc para encontrar os melhores parametros de cada modelo\n",
    "# define models\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "#svc = SVC()\n",
    "\n",
    "# define evaluation\n",
    "cv = model_selection.StratifiedKFold(n_splits=10)\n",
    "\n",
    "# define search space for decision tree\n",
    "space = dict()\n",
    "space['criterion'] = ['gini', 'entropy']\n",
    "space['min_samples_split'] = [2,3,5,7]\n",
    "space['max_depth'] = [3,5,6,7,9,11,13,15,17,19]\n",
    "space['min_samples_leaf'] = [2, 3]\n",
    "\n",
    "\n",
    "# define random search for decision tree\n",
    "search = RandomizedSearchCV(decisionTree, space, n_iter=50, scoring='accuracy', n_jobs=-1, cv=cv, random_state=SEED)\n",
    "\n",
    "# execute search\n",
    "result_tree = search.fit(X_train, y_train)\n",
    "\n",
    "# summarize result for decision tree\n",
    "print('=========Random Search Results for TREE==========')\n",
    "print('Best Score: %s' % result_tree.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeClassifier(**result_tree.best_params_, random_state=SEED)\n",
    "\n",
    "result_tree = decisionTree.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, decisionTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN (Livy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de decisão simples (Priscilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (Lucas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def f1_weighted(y_true, y_pred):\n",
    "  \"\"\" Função auxiliar para o cáulo da medida-f ponderada \"\"\"\n",
    "  return f1_score(y_true, y_pred, average=\"weighted\").round(3)\n",
    "\n",
    "def score_model(model, X, y, n_splits=10, n_repeats=3, scoring='f1_weighted', random_state=SEED):\n",
    "\n",
    "  cv = RepeatedStratifiedKFold(n_splits=n_splits, \n",
    "                               n_repeats=n_repeats, \n",
    "                               random_state=random_state)\n",
    "  \n",
    "  n_scores = cross_val_score(model, X, y, \n",
    "                             scoring=scoring, \n",
    "                             cv=cv, \n",
    "                             n_jobs=-1, \n",
    "                             error_score='raise')\n",
    "  \n",
    "  return f'{scoring.title()}: %.3f (%.3f)' % (n_scores.mean(), n_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa 1 (17min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo a lista de parâmetros e seus possíveis valores.\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": range(10, 101, 10),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Notem que a validação agora demora mais que com os modelos que usamos até então.\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=SEED), \n",
    "                    parameters,\n",
    "                    scoring  = \"f1_weighted\",\n",
    "                    n_jobs= -1, \n",
    "                    verbose=4,\n",
    "                    cv = cv)# Quando atribuímos um número inteiro (quantidade de folds) ao parâmetro cv, a validação cruzada é estratificada\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=SEED)\n",
    "print(\"Train >>\", score_model(model, X_train, y_train))\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Test score: \", f1_weighted(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa 2 (53min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo a lista de parâmetros e seus possíveis valores.\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": range(300, 601, 10),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Notem que a validação agora demora mais que com os modelos que usamos até então.\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=SEED), \n",
    "                    parameters,\n",
    "                    scoring  = \"f1_weighted\",\n",
    "                    n_jobs= -1, \n",
    "                    verbose=4,\n",
    "                    cv = 5)# Quando atribuímos um número inteiro (quantidade de folds) ao parâmetro cv, a validação cruzada é estratificada\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa 3 (27min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo a lista de parâmetros e seus possíveis valores.\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": range(400, 451, 3),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Notem que a validação agora demora mais que com os modelos que usamos até então.\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=SEED), \n",
    "                    parameters,\n",
    "                    scoring  = \"f1_weighted\",\n",
    "                    n_jobs= -1, \n",
    "                    verbose=4,\n",
    "                    cv = 5)# Quando atribuímos um número inteiro (quantidade de folds) ao parâmetro cv, a validação cruzada é estratificada\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo a lista de parâmetros e seus possíveis valores.\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": range(405, 415, 1),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Notem que a validação agora demora mais que com os modelos que usamos até então.\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=SEED), \n",
    "                    parameters,\n",
    "                    scoring  = \"f1_weighted\",\n",
    "                    n_jobs= -1, \n",
    "                    verbose=4,\n",
    "                    cv = 5)# Quando atribuímos um número inteiro (quantidade de folds) ao parâmetro cv, a validação cruzada é estratificada\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo a lista de parâmetros e seus possíveis valores.\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": range(1, 101, 1),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Notem que a validação agora demora mais que com os modelos que usamos até então.\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=SEED), \n",
    "                    parameters,\n",
    "                    scoring  = \"f1_weighted\",\n",
    "                    n_jobs= -1, \n",
    "                    verbose=4,\n",
    "                    cv = 5)# Quando atribuímos um número inteiro (quantidade de folds) ao parâmetro cv, a validação cruzada é estratificada\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incluindo mais parâmetros (57min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo a lista de parâmetros e seus possíveis valores.\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": [409,410,411],#range(407, 412, 1),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_depth': [10, 50, 100, None]#[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "}\n",
    "  \n",
    "\n",
    "# Notem que a validação agora demora mais que com os modelos que usamos até então.\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=SEED), \n",
    "                    parameters,\n",
    "                    scoring  = \"f1_weighted\",\n",
    "                    n_jobs= -1, \n",
    "                    verbose=4,\n",
    "                    cv = 3)# Quando atribuímos um número inteiro (quantidade de folds) ao parâmetro cv, a validação cruzada é estratificada\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_searchrf(X_train, y_train, parameters, SEED, metrica, k):\n",
    "    # Notem que a validação agora demora mais que com os modelos que usamos até então.\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(random_state=SEED), \n",
    "                    parameters,\n",
    "                    scoring  = \"f1_weighted\",\n",
    "                    n_jobs= -1, \n",
    "                    verbose=4,\n",
    "                    cv = 3)# Quando atribuímos um número inteiro (quantidade de folds) ao parâmetro cv, a validação cruzada é estratificada\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)\n",
    "    print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desempenho no teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(**best_params, random_state = SEED)\n",
    "\n",
    "print(\"Train >> \", score_model(model, X_train, y_train))\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Test score pós-validação: \", f1_weighted(y_test, model.predict(X_test)))\n",
    "\n",
    "model = RandomForestClassifier(random_state = SEED)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Test score PRÉ-validação: \", f1_weighted(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede neural MLP (Mari)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comitê de Redes Neurais (Laianna)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8003219c8c57211ee3be347d121ba14ebad7276cdae3d94be72d9e4e17f9edd5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
