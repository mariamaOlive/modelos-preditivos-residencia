{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Modelos preditivos - Dataset do Censo\n",
    "\n",
    "## Grupo:\n",
    "- Lucas Natan Correia Couri\n",
    "- Mariama Celi Serafim de Oliveira\n",
    "- Laianna Lana Virginio da Silva\n",
    "- Priscilla Amarante de Lima\n",
    "- Liviany Reis Rodrigues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 6138\n",
    "columns_name = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'class']\n",
    "df = pd.read_csv(\"Dados/adult.data\", names=columns_name, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explorar a base de dados para mostrar outliers, nivel de separatividade dos dados em relação as classes (grafico de dispersao), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workclass'] = df['workclass'].astype('category')\n",
    "df['education'] = df['education'].astype('category')\n",
    "df['marital-status'] = df['marital-status'].astype('category')\n",
    "df['occupation'] = df['occupation'].astype('category')\n",
    "df['relationship'] = df['relationship'].astype('category')\n",
    "df['race'] = df['race'].astype('category')\n",
    "df['sex'] = df['sex'].astype('category')\n",
    "df['native-country'] = df['native-country'].astype('category')\n",
    "df['class'] = df['class'].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolvendo o problema da Holanda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No dataset de treino há apenas uma obvservação como \" Holand-Netherlands\", diante do tamanho do dataset (mais de 30mil linhas) optou-se por remover essa única linha com native-country=\" Holand-Netherlands\" de forma a evitar problemas de ausência do valor no dataset de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['native-country']!=\" Holand-Netherlands\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenchendo dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratamento_faltantes(df, columns_name):\n",
    "    ## Printa os atributos com dados faltantes (\" ?\")\n",
    "    for coluna in columns_name:\n",
    "        if len(df[df[coluna] == \" ?\"]) > 0:\n",
    "            print(coluna)\n",
    "            print(len(df[df[coluna] == \" ?\"]))\n",
    "    \n",
    "    ## Tratamento dos dados faltantes, transforma para numerico, substitui \" ?\" por NaN e interpola os NaN\n",
    "    atr_faltantes = [\"workclass\", \"occupation\", \"native-country\"]\n",
    "    for atr in atr_faltantes:\n",
    "        categorias_atr = df.groupby(atr).sum().index.tolist()\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        label_encoder.fit(categorias_atr)\n",
    "        df[f\"{atr}-num\"] = label_encoder.transform(df[atr])\n",
    "        df[f\"{atr}-num\"] = df[f\"{atr}-num\"].replace(0, np.nan)\n",
    "        df[f\"{atr}-num\"] = df[f\"{atr}-num\"].interpolate(method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratamento_faltantes(df, columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for coluna in columns_name:\n",
    "#    if len(df[df[coluna] == \" ?\"]) > 0:\n",
    "#        print(coluna)\n",
    "#        print(len(df[df[coluna] == \" ?\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada atributo que tem dados faltantes vamos preencher utilizando a interpolação, para isso passamos para numerico antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atr_faltantes = [\"workclass\", \"occupation\", \"native-country\"]\n",
    "#for atr in atr_faltantes:\n",
    "#    categorias_atr = df.groupby(atr).sum().index.tolist()\n",
    "#    label_encoder = preprocessing.LabelEncoder()\n",
    "#    label_encoder.fit(categorias_atr)\n",
    "#    df[f\"{atr}-num\"] = label_encoder.transform(df[atr])\n",
    "#    df[f\"{atr}-num\"] = df[f\"{atr}-num\"].replace(0, np.nan)\n",
    "#    df[f\"{atr}-num\"] = df[f\"{atr}-num\"].interpolate(method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checando outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours-per-week'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours-per-week'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-gain'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-gain'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-loss'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital-loss'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1 = dados['idade_log'].quantile(q=0.25)\n",
    "#q3 = dados['idade_log'].quantile(q=0.75)\n",
    "#iqr = q3 - q1\n",
    "#print(iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colunas redundantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "education e education-num significam a mesma coisa, vamos utilizar education-num e dropar education (education-num já é a codificação ordinal de education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education-num'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: Plotar região"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequência das variáveis categóricas (Value counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['marital-status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando e processando conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Dados/adult.test\", names=columns_name, index_col=False, skiprows=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratamento_faltantes(df_test, columns_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação das variáveis categóricas (variáveis nominais, faremos One Hot Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoder(df):\n",
    "    colunas_cat = [\"workclass-num\",\"marital-status\", \"occupation-num\", \"relationship\", \"race\", \"sex\", \"native-country-num\"]\n",
    "    for coluna in colunas_cat:\n",
    "        print(coluna)\n",
    "        df_coluna = pd.get_dummies(df[coluna], prefix=coluna)\n",
    "        df = df.join(df_coluna)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = onehot_encoder(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = onehot_encoder(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando variáveis contínuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalize = MinMaxScaler()\n",
    "df[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]] = normalize.fit_transform(df[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]])\n",
    "df_test[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]] = normalize.fit_transform(df_test[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"age\", \"fnlwgt\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"education-num\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo conjuntos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop([\"class\", \"education\", \"workclass\", \"workclass-num\",\"marital-status\", \"occupation\", \"occupation-num\", \"relationship\", \"race\", \"sex\", \"native-country\", \"native-country-num\"], axis = 1).to_numpy()\n",
    "y_train = df[\"class\"].values\n",
    "X_test = df_test.drop([\"class\", \"education\", \"workclass\", \"workclass-num\",\"marital-status\", \"occupation\", \"occupation-num\", \"relationship\", \"race\", \"sex\", \"native-country\", \"native-country-num\"], axis = 1).to_numpy()\n",
    "y_test = df_test[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"class\", \"education\", \"workclass\", \"workclass-num\",\"marital-status\", \"occupation\", \"occupation-num\", \"relationship\", \"race\", \"sex\", \"native-country\", \"native-country-num\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Realizar busca com o gridsearch ou randonsearhc para encontrar os melhores parametros de cada modelo\n",
    "# define models\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "#svc = SVC()\n",
    "\n",
    "# define evaluation\n",
    "cv = model_selection.StratifiedKFold(n_splits=10)\n",
    "\n",
    "# define search space for decision tree\n",
    "space = dict()\n",
    "space['criterion'] = ['gini', 'entropy']\n",
    "space['min_samples_split'] = [2,3,5,7]\n",
    "space['max_depth'] = [3,5,6,7,9,11,13,15,17,19]\n",
    "space['min_samples_leaf'] = [2, 3]\n",
    "\n",
    "\n",
    "# define random search for decision tree\n",
    "search = RandomizedSearchCV(decisionTree, space, n_iter=50, scoring='accuracy', n_jobs=-1, cv=cv, random_state=SEED)\n",
    "\n",
    "# execute search\n",
    "result_tree = search.fit(X_train, y_train)\n",
    "\n",
    "# summarize result for decision tree\n",
    "print('=========Random Search Results for TREE==========')\n",
    "print('Best Score: %s' % result_tree.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeClassifier(**result_tree.best_params_, random_state=SEED)\n",
    "\n",
    "result_tree = decisionTree.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, decisionTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN (Livy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de decisão simples (Priscilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# define models\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "\n",
    "# define evaluation\n",
    "cv = model_selection.StratifiedKFold(n_splits=10)\n",
    "\n",
    "# define search space for decision tree\n",
    "space = dict()\n",
    "space['criterion'] = ['gini', 'entropy']\n",
    "space['min_samples_split'] = [2,15,5,22]\n",
    "space['max_depth'] = range(1,60)\n",
    "space['min_samples_leaf'] = [2, 6]\n",
    "\n",
    "\n",
    "# define random search for decision tree\n",
    "#search = RandomizedSearchCV(decisionTree, space, n_iter=50, scoring='accuracy', n_jobs=-1, cv=cv, random_state=SEED)\n",
    "search = GridSearchCV(decisionTree, space, scoring='accuracy', n_jobs=-1, cv=cv, verbose=4)\n",
    "\n",
    "\n",
    "# execute search\n",
    "result_tree = search.fit(X_train, y_train)\n",
    "\n",
    "# summarize result for decision tree\n",
    "print('=========Random Search Results for TREE==========')\n",
    "print('Best Score: %s' % result_tree.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciando\n",
    "tree_classifier = DecisionTreeClassifier(criterion='entropy', max_depth= 11, min_samples_leaf= 3, min_samples_split= 7, random_state=SEED)\n",
    "model = tree_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_representation = tree.export_text(tree_classifier)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotar a melhor árvore\n",
    "feature_names=df.drop([\"class\", \"education\", \"workclass\", \"workclass-num\",\"marital-status\", \"occupation\", \"occupation-num\", \"relationship\", \"race\", \"sex\", \"native-country\", \"native-country-num\"], axis = 1).columns\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(tree_classifier, \n",
    "                   feature_names=feature_names,  \n",
    "                  #  class_names=list(label_encoder.classes_),\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Árvore de decisão ilustrada\n",
    "from dtreeviz.trees import dtreeviz # remember to load the package\n",
    "\n",
    "viz = dtreeviz(clf, X, y,\n",
    "                target_name=\"target\",\n",
    "                fontname=\"Arial\",\n",
    "                title=\"Árvore de decisão ilustrada\",\n",
    "                title_fontsize=16,\n",
    "                feature_names=features,\n",
    "                orientation='LR',\n",
    "                scale=1.2,\n",
    "                class_names=list(label_encoder.classes_))\n",
    "\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (Lucas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def search_rf(parameters, cv, X_train, y_train, SEED):\n",
    "\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(random_state=SEED), \n",
    "                        parameters,\n",
    "                        scoring  = \"accuracy\",\n",
    "                        n_jobs= -1, \n",
    "                        verbose=4,\n",
    "                        cv = cv)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_score = grid_search.best_score_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)\n",
    "    print(best_score)\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa 1 (18min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": range(10, 301, 20),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "rf_try1 = search_rf(parameters, cv, X_train, y_train, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa 2 (47min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": range(300, 451, 10),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "rf_try2 = search_rf(parameters, cv, X_train, y_train, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa 3 (17min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": range(408, 413, 1),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "rf_try3 = search_rf(parameters, cv, X_train, y_train, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": [190,440,412],#range(407, 412, 1),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    'min_samples_leaf': [1, 4],\n",
    "    'min_samples_split': [2, 10]#,\n",
    "    #'max_depth': [10, 100, None]#[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "}\n",
    "\n",
    "rf_try4 = search_rf(parameters, cv, X_train, y_train, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desempenho no teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'criterion': 'gini', 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 440}\n",
    "best_rf = RandomForestClassifier(**rf_try4, random_state = SEED)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Score de teste:\", accuracy_score(y_test, best_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede neural MLP (Mari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.StratifiedKFold(n_splits=10)\n",
    "\n",
    "def gridsearch_mlp(X_train, y_train, parameters, metric, seed = SEED):\n",
    "    search = GridSearchCV(MLPClassifier(random_state = seed), parameters, scoring=metric,  n_jobs=-1, cv=cv, return_train_score=True, verbose=10)\n",
    "\n",
    "    result_mlp = search.fit(X_train, y_train)\n",
    "    print_result(result_mlp)\n",
    "    return result_mlp\n",
    "\n",
    "\n",
    "def randomsearch_mlp(X_train, y_train, parameters, metric, seed = SEED):\n",
    "    search = RandomizedSearchCV(MLPClassifier(random_state = seed), parameters, n_iter=100, n_jobs=-1, scoring=metric, cv=cv, random_state=seed, return_train_score=True, verbose=10)\n",
    "\n",
    "    result_mlp = search.fit(X_train, y_train)\n",
    "    print_result(result_mlp)\n",
    "    return result_mlp\n",
    "\n",
    "\n",
    "def print_result(result): \n",
    "    # summarize result \n",
    "    print('=========Random Search Results for MLP==========')\n",
    "    print('Best Score: %s' % result.best_score_)\n",
    "    print('Best Hyperparameters: %s' % result.best_params_) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentativa 1 (55 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space for MPL\n",
    "space = dict()\n",
    "space[\"hidden_layer_sizes\"] = [(4,4), (20,15),(50,50), (100,50), (50,100), (100, 250),(4,10,4),(20,10,5),(250, 100, 50)]\n",
    "space[\"activation\"] = [\"logistic\", \"tanh\", \"relu\", \"identity\"]\n",
    "space[\"solver\"] = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "\n",
    "result1 = randomsearch_mlp(X_train, y_train, space, \"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(result1.cv_results_)\n",
    "results.sort_values(by='rank_test_score', inplace=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentativa 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando leaning_rate e retirando algumas opções\n",
    "space = dict()\n",
    "space[\"hidden_layer_sizes\"] = [(4,4), (20,15),(50,50), (100,50), (50,100), (100, 250),(4,10,4),(20,10,5),(250, 100, 50)]\n",
    "space[\"activation\"] = [\"logistic\", \"tanh\", \"relu\"]\n",
    "space[\"solver\"] = [\"lbfgs\", \"adam\"]\n",
    "space[\"learning_rate\"] = [\"constant\", \"invscaling\", \"adaptive\"] \n",
    "\n",
    "result2 = gridsearch_mlp(X_train, y_train, space, \"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(result2.cv_results_)\n",
    "results.sort_values(by='rank_test_score', inplace=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentativa 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variando camadas e retirando alguns valores\n",
    "space = dict()\n",
    "space[\"hidden_layer_sizes\"] = [(50,30,20,10),(20,15),(20,20,20,20),(100, 250),(100, 250, 300,450),(250, 100, 50)]\n",
    "space[\"activation\"] = [\"tanh\"]\n",
    "space[\"solver\"] = [\"lbfgs\"]\n",
    "space[\"learning_rate\"] = [\"constant\", \"invscaling\", \"adaptive\"] \n",
    "\n",
    "result3 = gridsearch_mlp(X_train, y_train, space, \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentativa 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variando camadas e retirando alguns valores\n",
    "space = dict()\n",
    "space[\"hidden_layer_sizes\"] = [(5,5,5,5),(10,10,10,10),(50,50,50,50),(10,10,10,10,10)]\n",
    "space[\"activation\"] = [\"logistic\", \"tanh\"]\n",
    "space[\"solver\"] = [\"lbfgs\"]\n",
    "\n",
    "space[\"learning_rate\"] = [\"constant\", \"invscaling\", \"adaptive\"] \n",
    "\n",
    "result4 = gridsearch_mlp(X_train, y_train, space, \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comitê de Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state = SEED)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_bgc(X_test, y_test, X_train, y_train, SEED, num_e, hidden_l, max_iterations, max_samples):\n",
    "\n",
    "    parameters = {\n",
    "        \"n_estimators\": num_e,\n",
    "        \"max_samples\": max_samples\n",
    "    }\n",
    "    \n",
    "    gs_bgc_mlp = GridSearchCV(BaggingClassifier(MLPClassifier(hidden_layer_sizes = hidden_l,\n",
    "                                                              max_iter = max_iterations,\n",
    "                                                              random_state = SEED)),\n",
    "                              parameters,\n",
    "                              scoring = \"accuracy\",\n",
    "                              #cv = cv,\n",
    "                              n_jobs= -1\n",
    "                             )\n",
    "\n",
    "    gs_bgc_mlp.fit(X_train, y_train)\n",
    "    \n",
    "    gs_bgc_mlp.fit(X_train, y_train)\n",
    "\n",
    "    best_params = gs_bgc_mlp.best_params_\n",
    "\n",
    "    return best_params, gs_bgc_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_l = (10, 10)\n",
    "max_iterations = 200\n",
    "num_e = [10, 20]\n",
    "max_samples = [1000, 50]\n",
    "\n",
    "best_params, gs_bgc_mlp = val_bgc(X_test, y_test, X_train, y_train, SEED, num_e, hidden_l, max_iterations, max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params)\n",
    "means = gs_bgc_mlp.cv_results_[\"mean_test_score\"]\n",
    "stds = gs_bgc_mlp.cv_results_[\"std_test_score\"]\n",
    "\n",
    "for mean, std, params in zip(means, stds, gs_bgc_mlp.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs_bgc_mlp.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comitê Heterogêneo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8003219c8c57211ee3be347d121ba14ebad7276cdae3d94be72d9e4e17f9edd5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
