{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Dados/adult.data.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3104/1389085771.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcolumns_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'workclass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fnlwgt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'education'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'education-num'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'marital-status'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'occupation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'relationship'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'race'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'capital-gain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'capital-loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hours-per-week'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'native-country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dados/adult.data.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dados/adult.data.csv'"
          ]
        }
      ],
      "source": [
        "columns_name = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
        "df = pandas.read_csv(\"Dados/adult.data.csv\", names=columns_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análise Exploratória"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#5. Preparacao dos dados conduzida em outro script\n",
        "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
        "print(dataframe.shape)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "#6. Divisao da base de dados em treinamento, validacao e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=seed)\n",
        "\n",
        "#X_train_p, X_valid, y_train_p, y_valid = train_test_split(X_train, y_train, random_state=seed)\n",
        "\n",
        "#7. Realizar busca com o gridsearch ou randonsearhc para encontrar os melhores parametros de cada modelo\n",
        "# define models\n",
        "decisionTree = DecisionTreeClassifier()\n",
        "svc = SVC()\n",
        "\n",
        "# define evaluation\n",
        "cv = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "# define search space for decision tree\n",
        "space = dict()\n",
        "space['criterion'] = ['gini', 'entropy']\n",
        "space['min_samples_split'] = [2,3,5,7]\n",
        "space['max_depth'] = [3,5,6,7,9,11,13,15,17,19]\n",
        "space['min_samples_leaf'] = [2, 3]\n",
        "\n",
        "# defining parameter range for svm\n",
        "param_grid = {'C': [0.1, 1, 10,],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001],\n",
        "              'kernel': ['rbf']}\n",
        "\n",
        "# define random search for decision tree\n",
        "search = RandomizedSearchCV(decisionTree, space, n_iter=50, scoring='accuracy', n_jobs=4, cv=cv, random_state=seed)\n",
        "\n",
        "# execute search\n",
        "result_tree = search.fit(X_train, y_train)\n",
        "\n",
        "# summarize result for decision tree\n",
        "print('=========Random Search Results fro TREE==========')\n",
        "print('Best Score: %s' % result_tree.best_score_)\n",
        "print('Best Hyperparameters: %s' % result_tree.best_params_)\n",
        "\n",
        "# define random search for SVM\n",
        "search = RandomizedSearchCV(svc, param_grid, n_iter=10, scoring='accuracy', n_jobs=4, cv=cv, random_state=seed)\n",
        "\n",
        "# execute search\n",
        "result_svc = search.fit(X_train, y_train)\n",
        "\n",
        "# summarize result for SVM\n",
        "print('=========Random Search Results for SVM==========')\n",
        "print('Best Score: %s' % result_svc.best_score_)\n",
        "print('Best Hyperparameters: %s' % result_svc.best_params_)\n",
        "\n",
        "\n",
        "#8. Definicao dos modelos de classificacao com as melhores configuracoes\n",
        "# criacao dos modelos com os melhores parametros\n",
        "RFC = RandomForestClassifier(n_estimators=10,random_state=seed)\n",
        "svc = result_svc.best_estimator_\n",
        "DTC = result_tree.best_estimator_   #tree.DecisionTreeClassifier(criterion='entropy', random_state=seed)\n",
        "MLP = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,5), random_state=seed)\n",
        "BMLP = BaggingClassifier(base_estimator=MLP, n_estimators=10, random_state=seed)\n",
        "\n",
        "#adiciona os modelos em uma lista\n",
        "models = []\n",
        "models.append(('Arvore', DTC))\n",
        "models.append(('SVM', svc))\n",
        "models.append(('ComiteArvore', RFC))\n",
        "models.append(('RedeNeural', MLP))\n",
        "models.append(('ComiteRede', BMLP))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "#deficao da metrica a ser utilizada\n",
        "scoring = 'accuracy'\n",
        "\n",
        "#9. Definicao do modelo experimental\n",
        "#amostragem estratificada\n",
        "#kfold = cv\n",
        "\n",
        "#10 Execucao do modelo experimental\n",
        "#avaliacao de cada modelo nas amotragens estratificas\n",
        "print('\\nDesempenhos medios dos modelos:')\n",
        "for name, model in models:\n",
        "\tcv_results = model_selection.cross_val_score(model, X_train, y_train, cv=10, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "\n",
        "#11 Comparacao de modelos\n",
        "# Teste de hipotese analisando o p-value\n",
        "stat, p = stats.kruskal(results[0],results[1],results[2],results[3],results[4])\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('\\nSame distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('\\nDifferent distributions (reject H0)')\n",
        "print('\\nComparison stats', stat)\n",
        "\n",
        "print('Comparacao Arvore | SVM ->', stats.kruskal(results[0],results[1]))\n",
        "print('Comparacao Arvore | ComiteArvore ->', stats.kruskal(results[0],results[2]))\n",
        "print('Comparacao Arvore | RedeNeural ->',stats.kruskal(results[0],results[3]))\n",
        "print('Comparacao Arvore | CRNA ->',stats.kruskal(results[0],results[4]))\n",
        "print('Comparacao SVM | RedeNeural ->',stats.kruskal(results[2],results[3]))\n",
        "print('Comparacao SVM | ComiteRede ->',stats.kruskal(results[2],results[4]))\n",
        "print('Comparacao RedeNeural | ComiteRede ->',stats.kruskal(results[3],results[4]))\t\n",
        "\n",
        "#treinamento dos modelos no conjunto de treino completo (sem divisao de validacao)\n",
        "RFC.fit(X_train, y_train);\n",
        "svc.fit(X_train, y_train);\n",
        "DTC.fit(X_train, y_train);\n",
        "MLP.fit(X_train, y_train);\n",
        "BMLP.fit(X_train, y_train);\n",
        "\n",
        "#predicao de cada modelo para a base de teste\n",
        "Y_test_prediction_RFC = RFC.predict(X_test)\n",
        "Y_test_prediction_SVC = svc.predict(X_test)\n",
        "Y_test_prediction_DTC = DTC.predict(X_test)\n",
        "Y_test_prediction_MLP = MLP.predict(X_test)\n",
        "Y_test_prediction_BMLP = BMLP.predict(X_test)\n",
        "\n",
        "#12 Apresentacao de resultados\n",
        "print(\"\\nAcuracia Comite de Arvore: Treinamento\",  RFC.score(X_train, y_train),\" Teste\" ,RFC.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_RFC))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_RFC))\n",
        "\n",
        "print(\"\\nAcuracia SVC: Treinamento\",  svc.score(X_train, y_train),\" Teste\" ,svc.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_SVC))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_SVC))\n",
        "\n",
        "print(\"\\nAcuracia Arvore: Treinamento\",  DTC.score(X_train, y_train),\" Teste\" ,DTC.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_DTC))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_DTC))\n",
        "\n",
        "print(\"\\nAcuracia Rede Neural: Treinamento\",  MLP.score(X_train, y_train),\" Teste\" ,MLP.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_MLP))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_MLP))\n",
        "\n",
        "print(\"\\nAcuracia Comite RNA: Treinamento\",  BMLP.score(X_train, y_train),\" Teste\" ,BMLP.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_BMLP))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_BMLP))\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-zog1U9EwyU"
      },
      "outputs": [],
      "source": [
        "print(result.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UWv5CGPhD_h",
        "outputId": "6b166650-86ac-4ffc-e468-e1d9b049f4e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mann-Whitney Statistic: s=4597.000, p=0.163\n",
            "Same distributions (fail to reject H0)\n",
            "Wilcoxon Statistic: s=2314.000, p=0.468\n",
            "Same distributions (fail to reject H0)\n",
            "Kruskal-Wallis Statistic: s=0.970, p=0.325\n",
            "Same distributions (fail to reject H0)\n",
            "Friedman Statistic: s=9.360, p=0.009\n",
            "Different distributions (reject H0)\n"
          ]
        }
      ],
      "source": [
        "# Significance stats tests\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from scipy.stats import mannwhitneyu\n",
        "from scipy.stats import friedmanchisquare\n",
        "from scipy.stats import kruskal\n",
        "from scipy.stats import wilcoxon\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate three independent samples\n",
        "data1 = 5 * randn(100) + 50\n",
        "data2 = 5 * randn(100) + 50\n",
        "data3 = 5 * randn(100) + 52\n",
        "\n",
        "# compare samples\n",
        "stat, p = mannwhitneyu(data1, data2)\n",
        "print('Mann-Whitney Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')\n",
        "\n",
        "stat, p = wilcoxon(data1, data2)\n",
        "print('Wilcoxon Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')\n",
        "\n",
        "stat, p = kruskal(data1, data2, data3)\n",
        "print('Kruskal-Wallis Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')\n",
        "\n",
        "stat, p = friedmanchisquare(data1, data2, data3)\n",
        "print('Friedman Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p21shpaFfTsv"
      },
      "outputs": [],
      "source": [
        "# random search decision tree model on the pima-diabetes dataset\n",
        "from pandas import read_csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Leitura dos dados\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(\"pima-indians-diabetes.csv\", names=names)\n",
        "\n",
        "#Preparacao dos dados conduzida em outro script\n",
        "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
        "print(dataframe.shape)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "y = array[:,8]\n",
        "\n",
        "# define model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# define evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# define search space\n",
        "space = dict()\n",
        "space['criterion'] = ['gini', 'entropy']\n",
        "space['min_samples_split'] = [2,3,5,7]\n",
        "space['max_depth'] = [3,5,6,7,9,11,13,15,17,19]\n",
        "space['min_samples_leaf'] = [2, 3]\n",
        "\n",
        "# define random search\n",
        "search = RandomizedSearchCV(model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(X, y)\n",
        "\n",
        "# summarize result\n",
        "print('=========Random Search Results==========')\n",
        "print('Best Score: %s' % result.best_score_)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)\n",
        "\n",
        "# define grid search\n",
        "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(X, y)\n",
        "\n",
        "print('=========Grid Search Results==========')\n",
        "print('Best Score: %s' % result.best_score_)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI8dzY9yuM4G"
      },
      "outputs": [],
      "source": [
        "print(result.best_estimator_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Classificacao-diabetes-full.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
