{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#3. Leitura dos dados\n",
        "columns_name = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
        "df = pandas.read_csv(\"Dados/adult.data.csv\", names=columns_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análise Exploratória"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#5. Preparacao dos dados conduzida em outro script\n",
        "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
        "print(dataframe.shape)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "#6. Divisao da base de dados em treinamento, validacao e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=seed)\n",
        "\n",
        "#X_train_p, X_valid, y_train_p, y_valid = train_test_split(X_train, y_train, random_state=seed)\n",
        "\n",
        "#7. Realizar busca com o gridsearch ou randonsearhc para encontrar os melhores parametros de cada modelo\n",
        "# define models\n",
        "decisionTree = DecisionTreeClassifier()\n",
        "svc = SVC()\n",
        "\n",
        "# define evaluation\n",
        "cv = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "# define search space for decision tree\n",
        "space = dict()\n",
        "space['criterion'] = ['gini', 'entropy']\n",
        "space['min_samples_split'] = [2,3,5,7]\n",
        "space['max_depth'] = [3,5,6,7,9,11,13,15,17,19]\n",
        "space['min_samples_leaf'] = [2, 3]\n",
        "\n",
        "# defining parameter range for svm\n",
        "param_grid = {'C': [0.1, 1, 10,],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001],\n",
        "              'kernel': ['rbf']}\n",
        "\n",
        "# define random search for decision tree\n",
        "search = RandomizedSearchCV(decisionTree, space, n_iter=50, scoring='accuracy', n_jobs=4, cv=cv, random_state=seed)\n",
        "\n",
        "# execute search\n",
        "result_tree = search.fit(X_train, y_train)\n",
        "\n",
        "# summarize result for decision tree\n",
        "print('=========Random Search Results fro TREE==========')\n",
        "print('Best Score: %s' % result_tree.best_score_)\n",
        "print('Best Hyperparameters: %s' % result_tree.best_params_)\n",
        "\n",
        "# define random search for SVM\n",
        "search = RandomizedSearchCV(svc, param_grid, n_iter=10, scoring='accuracy', n_jobs=4, cv=cv, random_state=seed)\n",
        "\n",
        "# execute search\n",
        "result_svc = search.fit(X_train, y_train)\n",
        "\n",
        "# summarize result for SVM\n",
        "print('=========Random Search Results for SVM==========')\n",
        "print('Best Score: %s' % result_svc.best_score_)\n",
        "print('Best Hyperparameters: %s' % result_svc.best_params_)\n",
        "\n",
        "\n",
        "#8. Definicao dos modelos de classificacao com as melhores configuracoes\n",
        "# criacao dos modelos com os melhores parametros\n",
        "RFC = RandomForestClassifier(n_estimators=10,random_state=seed)\n",
        "svc = result_svc.best_estimator_\n",
        "DTC = result_tree.best_estimator_   #tree.DecisionTreeClassifier(criterion='entropy', random_state=seed)\n",
        "MLP = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,5), random_state=seed)\n",
        "BMLP = BaggingClassifier(base_estimator=MLP, n_estimators=10, random_state=seed)\n",
        "\n",
        "#adiciona os modelos em uma lista\n",
        "models = []\n",
        "models.append(('Arvore', DTC))\n",
        "models.append(('SVM', svc))\n",
        "models.append(('ComiteArvore', RFC))\n",
        "models.append(('RedeNeural', MLP))\n",
        "models.append(('ComiteRede', BMLP))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "#deficao da metrica a ser utilizada\n",
        "scoring = 'accuracy'\n",
        "\n",
        "#9. Definicao do modelo experimental\n",
        "#amostragem estratificada\n",
        "#kfold = cv\n",
        "\n",
        "#10 Execucao do modelo experimental\n",
        "#avaliacao de cada modelo nas amotragens estratificas\n",
        "print('\\nDesempenhos medios dos modelos:')\n",
        "for name, model in models:\n",
        "\tcv_results = model_selection.cross_val_score(model, X_train, y_train, cv=10, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "\n",
        "#11 Comparacao de modelos\n",
        "# Teste de hipotese analisando o p-value\n",
        "stat, p = stats.kruskal(results[0],results[1],results[2],results[3],results[4])\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('\\nSame distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('\\nDifferent distributions (reject H0)')\n",
        "print('\\nComparison stats', stat)\n",
        "\n",
        "print('Comparacao Arvore | SVM ->', stats.kruskal(results[0],results[1]))\n",
        "print('Comparacao Arvore | ComiteArvore ->', stats.kruskal(results[0],results[2]))\n",
        "print('Comparacao Arvore | RedeNeural ->',stats.kruskal(results[0],results[3]))\n",
        "print('Comparacao Arvore | CRNA ->',stats.kruskal(results[0],results[4]))\n",
        "print('Comparacao SVM | RedeNeural ->',stats.kruskal(results[2],results[3]))\n",
        "print('Comparacao SVM | ComiteRede ->',stats.kruskal(results[2],results[4]))\n",
        "print('Comparacao RedeNeural | ComiteRede ->',stats.kruskal(results[3],results[4]))\t\n",
        "\n",
        "#treinamento dos modelos no conjunto de treino completo (sem divisao de validacao)\n",
        "RFC.fit(X_train, y_train);\n",
        "svc.fit(X_train, y_train);\n",
        "DTC.fit(X_train, y_train);\n",
        "MLP.fit(X_train, y_train);\n",
        "BMLP.fit(X_train, y_train);\n",
        "\n",
        "#predicao de cada modelo para a base de teste\n",
        "Y_test_prediction_RFC = RFC.predict(X_test)\n",
        "Y_test_prediction_SVC = svc.predict(X_test)\n",
        "Y_test_prediction_DTC = DTC.predict(X_test)\n",
        "Y_test_prediction_MLP = MLP.predict(X_test)\n",
        "Y_test_prediction_BMLP = BMLP.predict(X_test)\n",
        "\n",
        "#12 Apresentacao de resultados\n",
        "print(\"\\nAcuracia Comite de Arvore: Treinamento\",  RFC.score(X_train, y_train),\" Teste\" ,RFC.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_RFC))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_RFC))\n",
        "\n",
        "print(\"\\nAcuracia SVC: Treinamento\",  svc.score(X_train, y_train),\" Teste\" ,svc.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_SVC))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_SVC))\n",
        "\n",
        "print(\"\\nAcuracia Arvore: Treinamento\",  DTC.score(X_train, y_train),\" Teste\" ,DTC.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_DTC))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_DTC))\n",
        "\n",
        "print(\"\\nAcuracia Rede Neural: Treinamento\",  MLP.score(X_train, y_train),\" Teste\" ,MLP.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_MLP))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_MLP))\n",
        "\n",
        "print(\"\\nAcuracia Comite RNA: Treinamento\",  BMLP.score(X_train, y_train),\" Teste\" ,BMLP.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_BMLP))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_BMLP))\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-zog1U9EwyU"
      },
      "outputs": [],
      "source": [
        "print(result.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UWv5CGPhD_h",
        "outputId": "6b166650-86ac-4ffc-e468-e1d9b049f4e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mann-Whitney Statistic: s=4597.000, p=0.163\n",
            "Same distributions (fail to reject H0)\n",
            "Wilcoxon Statistic: s=2314.000, p=0.468\n",
            "Same distributions (fail to reject H0)\n",
            "Kruskal-Wallis Statistic: s=0.970, p=0.325\n",
            "Same distributions (fail to reject H0)\n",
            "Friedman Statistic: s=9.360, p=0.009\n",
            "Different distributions (reject H0)\n"
          ]
        }
      ],
      "source": [
        "# Significance stats tests\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from scipy.stats import mannwhitneyu\n",
        "from scipy.stats import friedmanchisquare\n",
        "from scipy.stats import kruskal\n",
        "from scipy.stats import wilcoxon\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate three independent samples\n",
        "data1 = 5 * randn(100) + 50\n",
        "data2 = 5 * randn(100) + 50\n",
        "data3 = 5 * randn(100) + 52\n",
        "\n",
        "# compare samples\n",
        "stat, p = mannwhitneyu(data1, data2)\n",
        "print('Mann-Whitney Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')\n",
        "\n",
        "stat, p = wilcoxon(data1, data2)\n",
        "print('Wilcoxon Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')\n",
        "\n",
        "stat, p = kruskal(data1, data2, data3)\n",
        "print('Kruskal-Wallis Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')\n",
        "\n",
        "stat, p = friedmanchisquare(data1, data2, data3)\n",
        "print('Friedman Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p21shpaFfTsv"
      },
      "outputs": [],
      "source": [
        "# random search decision tree model on the pima-diabetes dataset\n",
        "from pandas import read_csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Leitura dos dados\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(\"pima-indians-diabetes.csv\", names=names)\n",
        "\n",
        "#Preparacao dos dados conduzida em outro script\n",
        "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
        "print(dataframe.shape)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "y = array[:,8]\n",
        "\n",
        "# define model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# define evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# define search space\n",
        "space = dict()\n",
        "space['criterion'] = ['gini', 'entropy']\n",
        "space['min_samples_split'] = [2,3,5,7]\n",
        "space['max_depth'] = [3,5,6,7,9,11,13,15,17,19]\n",
        "space['min_samples_leaf'] = [2, 3]\n",
        "\n",
        "# define random search\n",
        "search = RandomizedSearchCV(model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(X, y)\n",
        "\n",
        "# summarize result\n",
        "print('=========Random Search Results==========')\n",
        "print('Best Score: %s' % result.best_score_)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)\n",
        "\n",
        "# define grid search\n",
        "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(X, y)\n",
        "\n",
        "print('=========Grid Search Results==========')\n",
        "print('Best Score: %s' % result.best_score_)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI8dzY9yuM4G"
      },
      "outputs": [],
      "source": [
        "print(result.best_estimator_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Classificacao-diabetes-full.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
